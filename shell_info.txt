atom ~/.bash_profile
source ~/.bash_profile

-- web_scraper
scp -i ./.ssh/n_va_key_pair.pem ./Desktop/Denver_Clustering/generate_property_metrics.py ubuntu@54.209.254.250:~/

scp -i ./.ssh/n_va_key_pair.pem  - r ./Desktop/Denver_Project/census_api.py ubuntu@54.209.254.250:~/
-r would send folder

-spark cluster

scp -i ./.ssh/n_va_key_pair.pem ./Desktop/spark-aws/install_scripts/install_these root@ec2-54-152-20-165.compute-1.amazonaws.com:/root/

/Users/michael/spark-1.6.1-bin-hadoop1/ec2/spark-ec2 -k n_va_key_pair -i /Users/michael/.ssh/n_va_key_pair.pem  -r us-east-1 login spark_cluster


mongodb/bin/mongoimport --db denver_properties --collection liq_lic --type json --file ./Desktop/Denver_Project/liquor_lic.json --jsonArray


shp2pgsql -s 4326 /Users/michael/Desktop/Denver_Project/liquor_licenses/liquor_licenses.shp liqlic denver > denverlic.sql
psql --host denverclustering.cfoj7z50le0s.us-east-1.rds.amazonaws.com --port 5432 --username postgres --dbname denver --file denverlic.sql

shp2pgsql -s 4326 /Users/michael/Desktop/Denver_Project/census_tracts_2010/census_tracts_2010.shp census_tracts denver > denvertrac.sql
psql --host denverclustering.cfoj7z50le0s.us-east-1.rds.amazonaws.com --port 5432 --username postgres --dbname denver --file denvertrac.sql

pgsql2shp -f "/Users/michael/Desktop/parc" --host  denverclustering.cfoj7z50le0s.us-east-1.rds.amazonaws.com --port 5432 --username postgres --dbname denver public.parcels_upload

pgsql2shp -f parc3 -h denverclustering.cfoj7z50le0s.us-east-1.rds.amazonaws.com -u postgres -P quitden1222 denver "select gid, cast(gid as integer) as test, ccyrblt, geom from public.parcels where gid >= 169071"


COPY parcels TO '/Users/michael/Desktop/parcel_ex.csv' DELIMITER ',' CSV HEADER;
